# 가상 면접 사례로 배우는 대규모 시스템 설계 기초

## ch1 사용자 수에 따른 규모 확장성

- 비-관계성 데이터베이스가 바람직한 선택일 경우
  - 아주 낮은 응답 지연시간이 요구됨
  - 다루는 데이터가 비정형이라 관계형 데이터가 아님
  - 데이터를 직렬화하거나 역직렬화할 수 있기만 하면 됨.
  - 아주 많은 양의 데이터를 저장할 필요가 있음.
- 스케일 업
  - 수직적 규모 확장 프로세스
	- 고사양 자원을 추가하는 행위
	- 단점
  	- 규모 확장에 한계가 존재한다
  	- 장애에 대한 자동복구(failover) 방안이나 다중화(redundancy) 방안을 제시하지 않음
- 스케일 아웃
  - 수평적 규모 확장 프로세스
  - 더 많은 서버를 추가하여 성능을 개선하는 행위
- 로드밸런서
	- 부하 분산 집합에 속한 웹서버들에게 트레픽 부하를 고르게 분산하는 역할을 함.
- 데이터베이스 다중화
  - 쓰기 연산(Write operation) - Writer 에서만 지원
  - 읽기 연산(Read operation) - Writer, Reader에서 지원
  - 다중화시 이득
    - 더나은 성능: 모든 데이터 변경 연상은 Writer 데이터베이스 서버로만 전달되고, 읽기는 Reader 서버로 분산되어, 병렬로 처리될 수 있는 Query의 수가 늘어나 성능이 좋아진다.
    - 안전성(reliability): 자연 재해 등으로 일부 데이터베이스가 파괴되어도 데이터는 보존이 가능하다.
    - 가용성(availability): 하나의 데이터베이스에서 장애가 발생해도 다른 서버에 있는 데이터를 가져와 계속 서비스가 가능하다
- 캐시
  - 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소.
  - 주도형 캐시 전략(read-through caching strategy)
    - 캐시에 저장되어있는지 확인후, 있으면 그 데이터를 이용하여 전송. 없으면 DB에서 데이터를 가져와 저장하고 반환
  - 유의사항
    - 캐시는 어떤 상황에 바람직한가?
      - 데이터 갱신이 자주 일어나지 않으나 참조가 빈번하게 일어나는 곳
    - 어떤 데이터를 케시에 두어야 하는가?
      - 휘발성 메모리이기에 임시 데이터나 자주 읽히는 데이터에 대한 백업용도로 사용해야한다.
    - 캐시에 보관된 데이터는 어떻게 만료(expire)되는가?
      - 만료에 대한 정책을 정의해두고, 만료된 데이터는 캐시에서 삭제되도록 해야한다.
      - 기간은 데이터의 life cycle을 고려해서 지정한다
    - 일관성(consistency)은 어떻게 유지되는가?
      - 일관성: 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부
      - 일관성을 유지하기 어려운 이유
        - 캐시를 갱신하는 연산이 단일 트랜젝션으로 처리되지 않는 경우
        - 여러 지역에 걸쳐 시스템을 확장해 나가는 경우
      - [Scaling Memcache at Facebook](https://research.facebook.com/publications/scaling-memcache-at-facebook/)
    - 장애에는 어떻게 대처할 것인가?
      - 단일 장애 지점(Single Point of Failure, SPOF)를 피하기위해 여러 지역에 거쳐 캐시 서버를 분산시켜야 한다.
    - 캐시 메모리는 얼마나 크게 잡을 것인가?
      - 캐시 메모리가 작을때, 액세스 패턴에 따라서 데이터가 너무 자주 밀려나(eviction) 캐시 성능이 떨어지게됨.
      - 캐시 메모리를 과할당(overprivision)하여, 캐시에 보관될 데이터가 갑자기 늘어났을때 문제를 방지할 수 있음.
      - **<주해>** AWS 의 경우, 최소 4G 정도로 우선 작업을 해두고, 운영 중 메모리 70%정도 차게되면 타입을 변경하거나 하면 될듯.
    - 데이터 방출(eviction) 정책은 무엇인가?
      - 캐시가 꽉차서 추가로 데이터를 입력하지 못할때, 기존 데이터를 제거하는 방식
      - LRU(Least Recently Used) 마지막으로 사용된 시점이 가장 오래된 데이터를 제거하는 정책
      - LFU(Least Frequently Used) 사용된 빈도가 가장 낮은 데이터를 제거하는 정책
      - FIFO(First In First Out) 가장 먼저 캐시에 들어온 데이터를 가장 먼저 제거하는 정책
- 콘텐츠 전송 네트워크 (CDN)
  - 정적 콘텐츠를 전송하는 데 쓰이는, 지리적 분산된 서버의 네트워크
  - 동적 콘텐츠 캐싱
    - [AWS CloudFront를 이용한 Dynamic Content Caching](https://aws.amazon.com/ko/cloudfront/dynamic-content/)
    - [Amazon CloudFront를 활용하여 비용 효율적으로 동적 워크로드 전송을 가속화하고 보호하기](https://aws.amazon.com/ko/blogs/tech/accelerate-protect-and-make-dynamic-workloads-delivery-cost-efficient-with-amazon-cloudfront/)
    - [당근 발표 - API 앞단에 CloudFront를 세우다](https://www.youtube.com/watch?v=02UhM4wiSZg)
  - CDN 사용시 고려사항
    - 비용
      - 데이터 전송량에 따라 과금.
      - 최대한 데이터를 줄일 수 있는 방법을 마련하거나 캐싱이 필요하지 않은 데이터를 제공하지 않는다.
    - 적절한 만료 시한 설정
      - 시의성이 중요한(time-sensitive) 콘텐츠의 경우, 만료 시점을 적절하게 제공해야한다.
      - 너무 길게되면 콘텐츠의 변화가 너무 없을 수 있고, 너무 짧으면 원본 콘텐츠에 접근하는 경우가 늘어 안쓰는것만 못한 상태가 될 수 있다.
    - CDN 장애에 대한 대처 방안
      - 장애 발생시 원본 서버로부터 직접 콘텐츠를 전송할 수 있도록 구성하는것이 필요함.
      - **<주해>** CDN 자체가 죽었을 경우에 대해서 준비를 해야하나?
    - 콘텐츠 무효화(invalidation) 방법
      - 만료되지 않은 컨텐츠를 제거하고 새로운 것으로 교체하는 과정.
- Stateless 웹 계층
  - 웹 서비스 계층을 수평으로 확장하는 방법으로 상태 정보(사용자 세션 데이터와 같은)를 제거하는 것이 필요하다.
- 데이터 센터
  - **<주해>** AWS에서는 리전의 AZ(Availability Zone)에 해당된다.
  - 다중 데이터센터 아키텍처에서의 기술적 난제
    - 트래픽 우회
      - 올바른 데이터센터로 트래픽을 보내기 위한 효과적인 방법을 찾아야함.
    - 데이터 동기화(synchronization)
      - 데이터를 여러 데이터센터에 걸쳐 다중화 하는것이 필요하다.
      - [Netfilx TechBlog - Active-Active for Multi-Regional Resiliency](https://netflixtechblog.com/active-active-for-multi-regional-resiliency-c47719f6685b)
    - 테스트와 배포
      - 여러 데이터센터에서 문제없이 동작하도록 서비스를 테스트 해보는 것이 중요.
      - 동일한 서비스가 데이터센터에 설치되도록 하기위해 자동화된 배포 도구를 구성.
- 메시지 큐
  - 메시지의 무손실(durability, 메시지 쿠에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관된다는 특성)을 보장하는, 비동기 통신을 지원하는 컴포넌트
  - 서비스 또는 서버 간 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다.
- 로그, 메트릭, 자동화
  - 로그
    - 시스템의 오류와 문제들을 보다 쉽게 찾아낼 수 있도록 설정하는 것이 필요하다.
  - 메트릭
    - 시스템의 현 상태를 손쉽게 파악할 수 있다.
    - 호스트 단위 메트릭: CPU, 메모리, 디스크 I/O 등등
    - 종합(aggregated) 메트릭: 데이터베이스 계층에대한 성능, 캐시 계층에대한 성능
    - 핵심 비즈니스 메트릭: 일일 능동 사용자, 수익, 재방문 등.
  - 자동화
    - 시스템이 크고 복잡해지면 생산성을 높이기 위해 자동화 도구를 활용해야함.
- 데이터베이스의 규모 확장
  - 수직적 확장
    - 고성능 자원을 사용할 수 있도록 증설한다.
    - 약점
      - 하드웨어의 한계가 명확해 서버 한 대로 서비스를 감당하기는 힘들다.
      - SPOF(Single Point of Failure)로 인한 위험성이 크다
      - 비용이 많이 든다.
  - 수평적 확장
    - 샤딩(sharding) 대규모 데이터베이스를 샤드(shard)라고 부르는 작은 단위로 분할하는 기술.
      - 같은 스키마를 쓰지만 샤드에 보관되는 데이터는 중복이 존재할 수 없다.
    - 샤딩 전략 구현시 고려 사항
      - 샤딩 키(sharding key)를 어떻게 정하느냐 하는 것이다.
        - 샤딩 키 : 파티션 키(partition key)라고도 함. 데이터가 어떻게 분산할지를 정하는 하나이상의 칼럼으로 구성된다.
    - 샤딩 도입시 발생할 수 있는 문제
      - 데이터의 재 샤딩(resharding)
        - 데이터가 너무 많아져서 하나의 샤드로는 더 이상 감당하기 어려울때.
        - 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드에 비해 빨리 진행될 때. (샤드 소진(shard exhaustion)이라고 함)
      - Celebrity 문제
        - 핫스팟 키(hotspot key) 문제라기도 함.
        - 특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제.
      - 조인과 비정규화
        - 샤드로 나누게되면 조인이 힘들기에 비정규화하여 하나의 테이블에서 쿼리가 수행될 수 있도록 하는 것.
