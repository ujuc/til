# 가상 면접 사례로 배우는 대규모 시스템 설계 기초

## 1장. 사용자 수에 따른 규모 확장성

- 비-관계성 데이터베이스가 바람직한 선택일 경우
  - 아주 낮은 응답 지연시간이 요구됨
  - 다루는 데이터가 비정형이라 관계형 데이터가 아님
  - 데이터를 직렬화하거나 역직렬화할 수 있기만 하면 됨.
  - 아주 많은 양의 데이터를 저장할 필요가 있음.

- 스케일 업
  - 수직적 규모 확장 프로세스
  - 고사양 자원을 추가하는 행위
  - 단점
    - 규모 확장에 한계가 존재한다
    - 장애에 대한 자동복구(failover) 방안이나 다중화(redundancy) 방안을 제시하지 않음

- 스케일 아웃
  - 수평적 규모 확장 프로세스
  - 더 많은 서버를 추가하여 성능을 개선하는 행위

- 로드밸런서
  - 부하 분산 집합에 속한 웹서버들에게 트레픽 부하를 고르게 분산하는 역할을 함.

- 데이터베이스 다중화
  - 쓰기 연산(Write operation) - Writer 에서만 지원
  - 읽기 연산(Read operation) - Writer, Reader에서 지원
  - 다중화시 이득
    - 더 나은 성능: 모든 데이터 변경 연산은 Writer 데이터베이스 서버로만 전달되고, 읽기는 Reader 서버로 분산되어, 병렬로 처리될 수 있는 Query의 수가 늘어나 성능이 좋아진다.
    - 안전성(reliability): 자연 재해 등으로 일부 데이터베이스가 파괴되어도 데이터는 보존이 가능하다.
    - 가용성(availability): 하나의 데이터베이스에서 장애가 발생해도 다른 서버에 있는 데이터를 가져와 계속 서비스가 가능하다

- 캐시
  - 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소.
  - 주도형 캐시 전략(read-through caching strategy)
    - 캐시에 저장되어있는지 확인후, 있으면 그 데이터를 이용하여 전송. 없으면 DB에서 데이터를 가져와 저장하고 반환
  - 유의사항
    - 캐시는 어떤 상황에 바람직한가?
      - 데이터 갱신이 자주 일어나지 않으나 참조가 빈번하게 일어나는 곳
    - 어떤 데이터를 캐시에 두어야 하는가?
      - 휘발성 메모리이기에 임시 데이터나 자주 읽히는 데이터에 대한 백업용도로 사용해야한다.
    - 캐시에 보관된 데이터는 어떻게 만료(expire)되는가?
      - 만료에 대한 정책을 정의해두고, 만료된 데이터는 캐시에서 삭제되도록 해야한다.
      - 기간은 데이터의 life cycle을 고려해서 지정한다
    - 일관성(consistency)은 어떻게 유지되는가?
      - 일관성: 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부
      - 일관성을 유지하기 어려운 이유
        - 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우
        - 여러 지역에 걸쳐 시스템을 확장해 나가는 경우
      - [Scaling Memcache at Facebook](https://research.facebook.com/publications/scaling-memcache-at-facebook/)
    - 장애에는 어떻게 대처할 것인가?
      - 단일 장애 지점(Single Point of Failure, SPOF)를 피하기위해 여러 지역에 거쳐 캐시 서버를 분산시켜야 한다.
    - 캐시 메모리는 얼마나 크게 잡을 것인가?
      - 캐시 메모리가 작을때, 액세스 패턴에 따라서 데이터가 너무 자주 밀려나(eviction) 캐시 성능이 떨어지게됨.
      - 캐시 메모리를 과할당(overprivision)하여, 캐시에 보관될 데이터가 갑자기 늘어났을때 문제를 방지할 수 있음.
      - **<주해>** AWS 의 경우, 최소 4G 정도로 우선 작업을 해두고, 운영 중 메모리 70%정도 차게되면 타입을 변경하거나 하면 될듯.
    - 데이터 방출(eviction) 정책은 무엇인가?
      - 캐시가 꽉차서 추가로 데이터를 입력하지 못할때, 기존 데이터를 제거하는 방식
      - LRU(Least Recently Used) 마지막으로 사용된 시점이 가장 오래된 데이터를 제거하는 정책
      - LFU(Least Frequently Used) 사용된 빈도가 가장 낮은 데이터를 제거하는 정책
      - FIFO(First In First Out) 가장 먼저 캐시에 들어온 데이터를 가장 먼저 제거하는 정책

- 콘텐츠 전송 네트워크 (CDN)
  - 정적 콘텐츠를 전송하는 데 쓰이는, 지리적 분산된 서버의 네트워크
  - 동적 콘텐츠 캐싱
    - [AWS CloudFront를 이용한 Dynamic Content Caching](https://aws.amazon.com/ko/cloudfront/dynamic-content/)
    - [Amazon CloudFront를 활용하여 비용 효율적으로 동적 워크로드 전송을 가속화하고 보호하기](https://aws.amazon.com/ko/blogs/tech/accelerate-protect-and-make-dynamic-workloads-delivery-cost-efficient-with-amazon-cloudfront/)
    - [당근 발표 - API 앞단에 CloudFront를 세우다](https://www.youtube.com/watch?v=02UhM4wiSZg)
  - CDN 사용시 고려사항
    - 비용
      - 데이터 전송량에 따라 과금.
      - 최대한 데이터를 줄일 수 있는 방법을 마련하거나 캐싱이 필요하지 않은 데이터를 제공하지 않는다.
    - 적절한 만료 시한 설정
      - 시의성이 중요한(time-sensitive) 콘텐츠의 경우, 만료 시점을 적절하게 제공해야한다.
      - 너무 길게되면 콘텐츠의 변화가 너무 없을 수 있고, 너무 짧으면 원본 콘텐츠에 접근하는 경우가 늘어 안쓰는것만 못한 상태가 될 수 있다.
    - CDN 장애에 대한 대처 방안
      - 장애 발생시 원본 서버로부터 직접 콘텐츠를 전송할 수 있도록 구성하는것이 필요함.
      - **<주해>** CDN 자체가 죽었을 경우에 대해서 준비를 해야하나?
    - 콘텐츠 무효화(invalidation) 방법
      - 만료되지 않은 컨텐츠를 제거하고 새로운 것으로 교체하는 과정.

- Stateless 웹 계층
  - 웹 서비스 계층을 수평으로 확장하는 방법으로 상태 정보(사용자 세션 데이터와 같은)를 제거하는 것이 필요하다.

- 데이터 센터
  - **<주해>** AWS에서는 리전의 AZ(Availability Zone)에 해당된다.
  - 다중 데이터센터 아키텍처에서의 기술적 난제
    - 트래픽 우회
      - 올바른 데이터센터로 트래픽을 보내기 위한 효과적인 방법을 찾아야함.
    - 데이터 동기화(synchronization)
      - 데이터를 여러 데이터센터에 걸쳐 다중화 하는것이 필요하다.
      - [Netfilx TechBlog - Active-Active for Multi-Regional Resiliency](https://netflixtechblog.com/active-active-for-multi-regional-resiliency-c47719f6685b)
    - 테스트와 배포
      - 여러 데이터센터에서 문제없이 동작하도록 서비스를 테스트 해보는 것이 중요.
      - 동일한 서비스가 데이터센터에 설치되도록 하기위해 자동화된 배포 도구를 구성.

- 메시지 큐
  - 메시지의 무손실(durability, 메시지 큐에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관된다는 특성)을 보장하는, 비동기 통신을 지원하는 컴포넌트
  - 서비스 또는 서버 간 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다.

- 로그, 메트릭, 자동화
  - 로그
    - 시스템의 오류와 문제들을 보다 쉽게 찾아낼 수 있도록 설정하는 것이 필요하다.
  - 메트릭
    - 시스템의 현 상태를 손쉽게 파악할 수 있다.
    - 호스트 단위 메트릭: CPU, 메모리, 디스크 I/O 등등
    - 종합(aggregated) 메트릭: 데이터베이스 계층에 대한 성능, 캐시 계층에 대한 성능
    - 핵심 비즈니스 메트릭: 일일 능동 사용자, 수익, 재방문 등.
  - 자동화
    - 시스템이 크고 복잡해지면 생산성을 높이기 위해 자동화 도구를 활용해야함.

- 데이터베이스의 규모 확장
  - 수직적 확장
    - 고성능 자원을 사용할 수 있도록 증설한다.
    - 약점
      - 하드웨어의 한계가 명확해 서버 한 대로 서비스를 감당하기는 힘들다.
      - SPOF(Single Point of Failure)로 인한 위험성이 크다
      - 비용이 많이 든다.
  - 수평적 확장
    - 샤딩(sharding) 대규모 데이터베이스를 샤드(shard)라고 부르는 작은 단위로 분할하는 기술.
      - 같은 스키마를 쓰지만 샤드에 보관되는 데이터는 중복이 존재할 수 없다.
    - 샤딩 전략 구현시 고려 사항
      - 샤딩 키(sharding key)를 어떻게 정하느냐 하는 것이다.
        - 샤딩 키 : 파티션 키(partition key)라고도 함. 데이터가 어떻게 분산할지를 정하는 하나이상의 칼럼으로 구성된다.
    - 샤딩 도입시 발생할 수 있는 문제
      - 데이터의 재 샤딩(resharding)
        - 데이터가 너무 많아져서 하나의 샤드로는 더 이상 감당하기 어려울때.
        - 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드에 비해 빨리 진행될 때. (샤드 소진(shard exhaustion)이라고 함)
      - Celebrity 문제
        - 핫스팟 키(hotspot key) 문제라기도 함.
        - 특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제.
      - 조인과 비정규화
        - 샤드로 나누게되면 조인이 힘들기에 비정규화하여 하나의 테이블에서 쿼리가 수행될 수 있도록 하는 것.

## 2장 개략적인 규모 추정

- 개략적인 규모 추정(back-of-the-envelope estimation)은 보편적으로 통용되는 성능 수치상에서 사고 실험(thought experiments)을 행하여 추정치를 계산하는 행위로서, 어떤 설계가 요구사항에 부합할 것인지 보기 위한 것. - 제프 딘
- 고가용성
  - 시스템이 오랜 시간 동안 지속적으로 중단 없이 운영될 수 있는 능력을 지칭하는 용어.

- 개략적인 규모 추정과 관계된 면접에서 가장 중요한 것은 문제를 풀어 나가는 절차이다. 면접자가 보고 싶어하는 것은 문제 해결 능력이다.
  - 팁
    - 근사치를 활용한 계산(rounding and approximation): 적절한 근사치를 활용하여 시간을 절약.
    - 가정(assumption): 적어두고 나중에 살펴볼 수 있도록 할것.
    - 단위(unit)을 붙여라.
    - QPS, 최대 QPS, 저장소 요구량, 캐시 요구량, 서버 수 등을 추정하는 것이 가장 많이 출제된다.

## 3장 시스템 설계 면접 공략법

- 시스템 설계 면접
  - 두 명의 동료가 모호한 문제를 풀기 위해 협력하여 그 해결책을 찾아내는 과정에 대한 시뮬레이션.
  - 설계 기술을 시연하는 자리이고, 설계 과정에서 내린 결정들에 대한 방어 능력을 보이는 자리이며, 면접관의 피드백을 건설적인 방식으로 처리할 자질이 있음을 보이는 자리.

- 면접관의 일차 목표는 여러분의 능력을 평가하는 것이다.

- 효과적인 면접을 위한 4단계 접근법
  - 1단계 문제 이해 및 설계 범위 확정
    - 요구 사항을 완전히 이해하지 않고 답을 내놓는 행위는 아주 엄청난 부정적 신호다.
    - 정답따위는 없다.
    - 깊이 생각하고 질문하여 요구사항과 가정들을 분명히 하라.
    - 엔지니어가 가져야 할 가장 중요한 기술 중 하나는 올바른 질문을 하는 것, 적절한 가정을 하는 것, 그리고 시스템 구축에 필요한 정보를 모으는 것이다.
  - 2단계 개략적인 설계안 제시 및 동의 구하기
    - 설계안에 대한 최초 청사진을 제시하고 의견 구하기
      - 면접관을 마치 팀원인 것처럼 대하라.
    - 화이트보드나 종이에 핵심 컴포넌트를 포함하는 다이어그램을 그려라.
    - 최초 설계안이 시스템 규모에 관계된 제약사항들을 만족하는지를 개략적으로 계산해 보라.
  - 3단계 상세 설계
    - 설계 대상 컴포넌트 사이의 우선순위를 정하는 것.
    - 특정 시스템 컴포넌트들의 세부사항을 깊이 있게 설명하는 것을 보길 원한다.
    - 시간 관리에도 특별히 주의를 기울여야 한다.
  - 4단계 마무리
    - 추가 논의 할 수 있는 몇가지 지침
      - 면접관이 시스템 병목구간, 혹은 좀 더 개선 가능한 지점을 찾아내라 주문할 수 있다. 거기다 대고 여러분의 설계가 완벽하다거나 개선할 부분이 없다는 답은 하지 않도록 하자.
      - 비판적 사고 능력을 보이고, 마지막으로 좋은 인상을 남길 기회다.
      - 만든 설계를 한번 다시 요약해주는 것도 도움이 될 수 있다.
      - 오류가 발생하면 무슨 일이 생기는지 따져보면 흥미로울 것이다.
      - 운영 이슈도 논의할 가치가 충분하다.
        - 메트릭은 어떻게 수집하고 모니터링 할 것인가? 로그는? 어떻게 배포할 것인가?
      - 미래에 닥칠 규모 확장 요구에 어떻게 대처할 것인가?
      - 시간이 남았을때, 필요하지만 다루지 못했던 세부적 개선사항들을 제안할 수 있다.
    - 면접 세션에서 해야할 것
      - 질문을 통해 확인(clarification)하라. 스스로 내린 가정이 옳다고 믿고 진행하지 말라.
      - 문제의 요구사항을 이해하라.
      - 정답이나 최선의 답안 같은 것은 없다는 점을 명심하라. 요구사항을 정확하게 이해했는지 다시 확인하라.
      - 면접관이 여러분의 사고 흐름을 이해할 수 있도록 하라.
      - 가능하다면 여러 해법을 함께 제시하라.
      - 개략적 설계에 면접관이 동의하면, 각 컴포넌트의 세부사항을 설명하기 시작하라. 가장 중요한 컴포넌트부터 진행하라.
      - 면접관의 아이디어를 이끌어 내라. 좋은 면접관은 여러분과 같은 팀원처럼 협력한다.
      - 포기하지 말라.
    - 면접 세션에서 하지 말아야 할 것
      - 전형적인 면접 문제들에도 대비하지 않은 상태에서 면접장에 가지 말라.
      - 요구사항이나 가정들을 분명히 하지 않은 상태에서 설계를 제시하지 말라.
      - 처음부터 특정 컴포넌트의 세부사항을 너무 깊이 설명하지 말라. 개략적 설계를 마친 뒤에 세부사항을 나아가라.
      - 진행 중에 막혔다면, 힌트를 청하기를 주저하지 말라.
      - 설계안을 내놓은 순간 면접이 끝난다고 생각하지 말라. 의견을 일찍, 그리고 자주 구하라.

## Ch4 처리율 제한 장치의 설계

- 처리율 제한 장치(rate limiter) : 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)를 제어하기 위한 장치
  - 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한하는 것과 같은 예임.
  - API 요청 횟수가 제한 장치에 정의된 임계치(threshold)를 넘어서면 추가로 도달한 모든 호출은 처리가 중단(block)된다.
- API에 처리율 제한 장치를 두면 좋은 점
  - DoS(Denial of service) 공격에 의한 자원 고갈(resource starvation)을 방지 가능
  - 비용 절감. 추가 요청에 대한 처리를 제한하면 서버를 많이 두지 않아도 되고, 우선순위가 높은 API에 더 많은 자원을 할당할 수 있다.
  - 서버 과부하를 막는다. bot에서 오는 트래픽이나 사용자의 잘못된 이용 패턴으로 유발된 트래픽을 걸러내는데 처리율 제한을 활용할 수 있다.

### 1단계 문제 이해 및 설계 범위 확정

- 시스템 요구사항
  - 설정된 처리율을 초과하는 요청은 정확하게 제한함.
  - 낮은 응답시간 - HTTP 응답시간에 나쁜 영향을 주어서는 안된다.
  - 가능한 한 적은 메모리를 사용해야한다.
  - 분산형 처리율 제한(distributed rate limiting) - 하나의 rate limiter로 여러 서버나 프로세스에서 공유할 수 있어야한다.
  - 예외 처리 - 요청이 제한되었을때, 그 사실을 사용자에게 분명하게 보여줘야 한다.
  - 높은 결함 감내성(fault tolerance) - rate limiter 에 장애가 발생하더라도 전체 시스템에 영향을 주어서는 안된다.

### 2단계 개략적 설계안 제시 및 동의 구하기

- 클라이언트 요청은 쉽게 위조가 가능하기에 rate limiter를 설정하는것은 위험하다.
- Rate limiter를 서버나, 미들웨어에 두어 통제하는것이 지금은 좋은 방법이다.
- Rate limiter 를 설계시 고려사항
  - 현재 사용하고 있는 기술 스택을 점검하여, 서버 측 구현을 지원하기 충분할 정도로 효율이 높은지 확인.
  - 서비스에 맞는 처리율 제한 알고리즘을 찾아라.
  - 마이크로서비스에 기반한 구성이라면, rate limiter 또한 게이트웨이 기능에 추가해야할 수 있다.
  - Rate limiter 서비스를 직접 만드는데는 시간이 든다. 상용 API 게이트웨이를 고려하라.

#### Rate limiter 알고리즘

- 토큰 버킷 token bucket
  - 동작 원리
    - 버킷에 토큰이 담길 수 있는 한계가 있고, 그것을 overflow 하게된다.
    - 토큰은 refill rate 를 통해서 특정 시간마다 초기화된다.
    - 하나의 요청이 들어오면 토큰 하나를 사용하게되고, 토큰이 하나도 없으면 drop 한다.
  - 인자
    - 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수
    - 토큰 공급률 (refill rate): 초당 몇 개의 토큰이 버킷에 공급되는가?
  - 사례
    - API 엔드포인트마다 별도의 버킷을 둔다.
      - 사용자마다 하루에 한 번 포스팅 (1 bucket)을 할 수 있고, 친구는 150명까지 추가 (1 bucket)할 수 있고, 좋아요 버튼은 다섯 번까지 (1 bucket)해서 사용자마다 3개의 버킷을 가지게됨.
  - 장점
    - 구현이 쉽다.
    - 메모리 사용 측면에서 효율적임.
    - 짧은 시간에 집중되는 트래픽 (burst of traffic)도 처리 가능. 버킷에 남은 토큰이 있기만 하면 요청은 시스템에 도달.
  - 단점
    - 두 개의 인자 (버킷 크기, 토큰 공급률)을 적절하게 튜닝하는 것이 까다롭다.

- 누출 버킷 leaky bucket
  - FIFO (First-In-First-Out) 큐로 구현.
  - 동작 원리
    - 요청을 받게 되면 큐에 요청을 추가하거나 가득차있으면 버린다.
    - 지정된 시간마다 큐에서 요청을 꺼내 처리한다.
  - 인자
    - 버킷 크기: 큐 사이즈와 같은 값
    - 처리율 (overflow rate): 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값. 초단위로 표현
  - 장점
    - 큐의 크기가 제한되어있어 메모리 사용량 측면에서 효율적
    - 고정된 처리율을 갖고 있기에 안정적인 출력(stable overflow rate)이 필요한 경우 적합함.
  - 단점
    - 단시간에 많은 트래픽이 몰리는 경우, 요청이 쌓이며, 그 요청들이 제때 처리되지 못할 경우, 최신 요청들이 버려지게 된다.
    - 두개의 인자를 올바르게 튜닝하기 까다로울 수 있음.

- 고정 윈도 카운터 fixed window counter
  - 동작 원리
    - 타임라인을 고정된 간격의 윈도(window)를 나누고, 각 윈도마다 카운터(counter)를 붙인다.
    - 요청이 접수될때마다 이 카운터의 값은 1씩 증가.
    - 이 카운터의 값이 사전에 설정된 임계치(threshold)에 도달하면 새로운 요청은 새 윈도가 열릴때까지 버려진다.
  - 장점
    - 메모리 효율이 좋다
    - 이해하기 쉽다
    - 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다
  - 단점
    - 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게된다.

- 이동 윈도 로그 sliding window log
  - 동작 원리
    - 요청의 타임스템프를 추적. 타임스템프 데이터는 보통 레디스의 정렬 집합과 같은 캐시에 보관.
    - 새요청이 오면 만료된 타임스탬프를 제거한다.
    - 새 요청의 타임스탬프를 로그에 추가한다
    - 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그렇지 않은 경우에는 처리를 거부한다.
  - 장점
    - 처리율 제한 메커니즘은 아주 정교하다. 어느 순간의 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.
  - 단점
    - 다량의 메모리를 사용하는데, 거부된 요청의 타임스탬프도 보관하기 때문임.

- 이동 윈도 카운터 sliding window counter
  - 고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한것.
  - 장점
    - 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.
    - 메모리 효율이 좋다
  - 단점
    - 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨함.

### 3단계 상세 설계

- 처리율 제한 규칙
- 처리율 한도 초과 트래픽의 처리
- 분산 환경에서의 처리율 제한 장치 구현
  - 두가지 어려운 문제가 있음.
  - 경쟁 조건(race condition)
    - 경쟁 조건 문제를 해결하는 방법은 lock이다.
    - 루아(Lua) 스크립트, 정렬 집합을 사용하는 것.
  - 동기화(synchronization)
- 성능 최적화
  - 지연시간
  - 최종 일관성 모델(eventual consistency model)
- 모니터링
  - 채택된 처리율 제한 알고리즘이 효과적
  - 정의한 처리율 제한 규칙이 효과적

### 4단계 마무리

- hard 또는 soft 처리율 제한
  - hard 처리율 제한: 요청 개수는 임계치를 절대 넘어설 수 없다.
  - soft 처리율 제한: 요청 개수는 잠시동안은 임계치를 넘어설 수 있다.
- 다양한 계층에서의 처리율 제한
- 처리율 제한을 회피하는 방법, 클라이언트를 어떻게 설계하는 것이 최선인가?

## 5장 안정 해시 설계

- 스케일 아웃을 위하여 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요함.

### 해시 키 재배치(rehash) 문제

- 해시 함수
  - `N`은 서버의 개수

```
serverIndex = hash(key) % N
```

- 서버 풀 크기가 고정되어있거나, 데이터 분포가 균등할때는 잘 동작함.
- 서버가 추가되거나 기존 서버가 삭제되면 문제가 발생하게됨.
  - 데이터가 다른 서버로 재분배가 되면서 클라이언트에서는 데이터가 없는 엉뚱한 서버에 접속할 가능성이 발생하게됨.

### 안정 해시

- 해시 테이블 크기가 조정될 떄 평균적으로 오직 k/n개의 키만 재배치하는 해시 기술이다. 여기서 k는 키의 개수이고, n은 슬롯(slot)의 개수다. 이와 달리 전통적인 해시 테이블은 슬롯의 수가 바뀌면 거의 대부분 키를 재배치한다.
- 해시 공간을 일렬로 구성하기도 하지만, 첫번째 공간과 마지막 공간을 연결해서 해시 링을 만들어서 설명을 하는데. 이건 설명을 쉽게 하려고 하는것같다.

- 안정 해시 알고리즘의 기본 절차
  - 서버와 키를 균등 분포(uniform distribution) 해시 함수를 사용해 해시 링에 배치한다.
  - 키의 위치에서 링을 시계 방향으로 탐색하다 만나는 최초의 서버의 키가 저장될 서버다.

- 기본 구현법의 두가지 문제
  1. 서버가 추가되거나 삭제되는 상황을 감안하면 파티션(partition)의 크기를 유지하는 게 불가능하다.
  - 파티션은 인접한 서버 사이의 해시 공간을 가르킨다.
  2. 키의 균등 분포(uniform distribution)을 달성하기가 어렵다.

- 문제 해결하기 위해 제안된 기법
  - 가상 노드: 실제 노드 또는 서버러를 가리키는 노드. 하나의 서버는 링 위에 여러개의 가상 노드를 가질 수 있다.
  - 가상 노드의 개수를 늘리면 키의 분포는 점점 더 균등해진다. 표준 편차가 작아져서 데이터가 더욱 균등하게 분포되기 때문임.

- 재배치할 키 결정
  - 항상 키는 서버의 시계 방향에 있는 서버로 배치된다.

### 안정 해시의 이점

- 서버가 추가되거나 삭제될 때 재배치되는 키의 수가 최소화된다.
- 데이터가 보다 균등하게 분포하게 되므로 수평적 규모 확장성을 달성하기 쉽다.
- 핫스팟 키 문제를 줄인다. 특정한 샤드에 대한 접근이나 지나치게 빈번하면서 서버 과부하 문제가 생길 수 있다. 안정 해시는 데이터를 좀 더 고르게 분배하므로 이런 문제가 생길 가능성을 줄인다.
