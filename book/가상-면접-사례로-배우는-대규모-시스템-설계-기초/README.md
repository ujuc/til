# 가상 면접 사례로 배우는 대규모 시스템 설계 기초

## 1장. 사용자 수에 따른 규모 확장성

- 비-관계성 데이터베이스가 바람직한 선택일 경우
  - 아주 낮은 응답 지연시간이 요구됨
  - 다루는 데이터가 비정형이라 관계형 데이터가 아님
  - 데이터를 직렬화하거나 역직렬화할 수 있기만 하면 됨.
  - 아주 많은 양의 데이터를 저장할 필요가 있음.

- 스케일 업
  - 수직적 규모 확장 프로세스
  - 고사양 자원을 추가하는 행위
  - 단점
    - 규모 확장에 한계가 존재한다
    - 장애에 대한 자동복구(failover) 방안이나 다중화(redundancy) 방안을 제시하지 않음

- 스케일 아웃
  - 수평적 규모 확장 프로세스
  - 더 많은 서버를 추가하여 성능을 개선하는 행위

- 로드밸런서
  - 부하 분산 집합에 속한 웹서버들에게 트레픽 부하를 고르게 분산하는 역할을 함.

- 데이터베이스 다중화
  - 쓰기 연산(Write operation) - Writer 에서만 지원
  - 읽기 연산(Read operation) - Writer, Reader에서 지원
  - 다중화시 이득
    - 더 나은 성능: 모든 데이터 변경 연산은 Writer 데이터베이스 서버로만 전달되고, 읽기는 Reader 서버로 분산되어, 병렬로 처리될 수 있는 Query의 수가 늘어나 성능이 좋아진다.
    - 안전성(reliability): 자연 재해 등으로 일부 데이터베이스가 파괴되어도 데이터는 보존이 가능하다.
    - 가용성(availability): 하나의 데이터베이스에서 장애가 발생해도 다른 서버에 있는 데이터를 가져와 계속 서비스가 가능하다

- 캐시
  - 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소.
  - 주도형 캐시 전략(read-through caching strategy)
    - 캐시에 저장되어있는지 확인후, 있으면 그 데이터를 이용하여 전송. 없으면 DB에서 데이터를 가져와 저장하고 반환
  - 유의사항
    - 캐시는 어떤 상황에 바람직한가?
      - 데이터 갱신이 자주 일어나지 않으나 참조가 빈번하게 일어나는 곳
    - 어떤 데이터를 캐시에 두어야 하는가?
      - 휘발성 메모리이기에 임시 데이터나 자주 읽히는 데이터에 대한 백업용도로 사용해야한다.
    - 캐시에 보관된 데이터는 어떻게 만료(expire)되는가?
      - 만료에 대한 정책을 정의해두고, 만료된 데이터는 캐시에서 삭제되도록 해야한다.
      - 기간은 데이터의 life cycle을 고려해서 지정한다
    - 일관성(consistency)은 어떻게 유지되는가?
      - 일관성: 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부
      - 일관성을 유지하기 어려운 이유
        - 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우
        - 여러 지역에 걸쳐 시스템을 확장해 나가는 경우
      - [Scaling Memcache at Facebook](https://research.facebook.com/publications/scaling-memcache-at-facebook/)
    - 장애에는 어떻게 대처할 것인가?
      - 단일 장애 지점(Single Point of Failure, SPOF)를 피하기위해 여러 지역에 거쳐 캐시 서버를 분산시켜야 한다.
    - 캐시 메모리는 얼마나 크게 잡을 것인가?
      - 캐시 메모리가 작을때, 액세스 패턴에 따라서 데이터가 너무 자주 밀려나(eviction) 캐시 성능이 떨어지게됨.
      - 캐시 메모리를 과할당(overprivision)하여, 캐시에 보관될 데이터가 갑자기 늘어났을때 문제를 방지할 수 있음.
      - **<주해>** AWS 의 경우, 최소 4G 정도로 우선 작업을 해두고, 운영 중 메모리 70%정도 차게되면 타입을 변경하거나 하면 될듯.
    - 데이터 방출(eviction) 정책은 무엇인가?
      - 캐시가 꽉차서 추가로 데이터를 입력하지 못할때, 기존 데이터를 제거하는 방식
      - LRU(Least Recently Used) 마지막으로 사용된 시점이 가장 오래된 데이터를 제거하는 정책
      - LFU(Least Frequently Used) 사용된 빈도가 가장 낮은 데이터를 제거하는 정책
      - FIFO(First In First Out) 가장 먼저 캐시에 들어온 데이터를 가장 먼저 제거하는 정책

- 콘텐츠 전송 네트워크 (CDN)
  - 정적 콘텐츠를 전송하는 데 쓰이는, 지리적 분산된 서버의 네트워크
  - 동적 콘텐츠 캐싱
    - [AWS CloudFront를 이용한 Dynamic Content Caching](https://aws.amazon.com/ko/cloudfront/dynamic-content/)
    - [Amazon CloudFront를 활용하여 비용 효율적으로 동적 워크로드 전송을 가속화하고 보호하기](https://aws.amazon.com/ko/blogs/tech/accelerate-protect-and-make-dynamic-workloads-delivery-cost-efficient-with-amazon-cloudfront/)
    - [당근 발표 - API 앞단에 CloudFront를 세우다](https://www.youtube.com/watch?v=02UhM4wiSZg)
  - CDN 사용시 고려사항
    - 비용
      - 데이터 전송량에 따라 과금.
      - 최대한 데이터를 줄일 수 있는 방법을 마련하거나 캐싱이 필요하지 않은 데이터를 제공하지 않는다.
    - 적절한 만료 시한 설정
      - 시의성이 중요한(time-sensitive) 콘텐츠의 경우, 만료 시점을 적절하게 제공해야한다.
      - 너무 길게되면 콘텐츠의 변화가 너무 없을 수 있고, 너무 짧으면 원본 콘텐츠에 접근하는 경우가 늘어 안쓰는것만 못한 상태가 될 수 있다.
    - CDN 장애에 대한 대처 방안
      - 장애 발생시 원본 서버로부터 직접 콘텐츠를 전송할 수 있도록 구성하는것이 필요함.
      - **<주해>** CDN 자체가 죽었을 경우에 대해서 준비를 해야하나?
    - 콘텐츠 무효화(invalidation) 방법
      - 만료되지 않은 컨텐츠를 제거하고 새로운 것으로 교체하는 과정.

- Stateless 웹 계층
  - 웹 서비스 계층을 수평으로 확장하는 방법으로 상태 정보(사용자 세션 데이터와 같은)를 제거하는 것이 필요하다.

- 데이터 센터
  - **<주해>** AWS에서는 리전의 AZ(Availability Zone)에 해당된다.
  - 다중 데이터센터 아키텍처에서의 기술적 난제
    - 트래픽 우회
      - 올바른 데이터센터로 트래픽을 보내기 위한 효과적인 방법을 찾아야함.
    - 데이터 동기화(synchronization)
      - 데이터를 여러 데이터센터에 걸쳐 다중화 하는것이 필요하다.
      - [Netfilx TechBlog - Active-Active for Multi-Regional Resiliency](https://netflixtechblog.com/active-active-for-multi-regional-resiliency-c47719f6685b)
    - 테스트와 배포
      - 여러 데이터센터에서 문제없이 동작하도록 서비스를 테스트 해보는 것이 중요.
      - 동일한 서비스가 데이터센터에 설치되도록 하기위해 자동화된 배포 도구를 구성.

- 메시지 큐
  - 메시지의 무손실(durability, 메시지 큐에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관된다는 특성)을 보장하는, 비동기 통신을 지원하는 컴포넌트
  - 서비스 또는 서버 간 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다.

- 로그, 메트릭, 자동화
  - 로그
    - 시스템의 오류와 문제들을 보다 쉽게 찾아낼 수 있도록 설정하는 것이 필요하다.
  - 메트릭
    - 시스템의 현 상태를 손쉽게 파악할 수 있다.
    - 호스트 단위 메트릭: CPU, 메모리, 디스크 I/O 등등
    - 종합(aggregated) 메트릭: 데이터베이스 계층에 대한 성능, 캐시 계층에 대한 성능
    - 핵심 비즈니스 메트릭: 일일 능동 사용자, 수익, 재방문 등.
  - 자동화
    - 시스템이 크고 복잡해지면 생산성을 높이기 위해 자동화 도구를 활용해야함.

- 데이터베이스의 규모 확장
  - 수직적 확장
    - 고성능 자원을 사용할 수 있도록 증설한다.
    - 약점
      - 하드웨어의 한계가 명확해 서버 한 대로 서비스를 감당하기는 힘들다.
      - SPOF(Single Point of Failure)로 인한 위험성이 크다
      - 비용이 많이 든다.
  - 수평적 확장
    - 샤딩(sharding) 대규모 데이터베이스를 샤드(shard)라고 부르는 작은 단위로 분할하는 기술.
      - 같은 스키마를 쓰지만 샤드에 보관되는 데이터는 중복이 존재할 수 없다.
    - 샤딩 전략 구현시 고려 사항
      - 샤딩 키(sharding key)를 어떻게 정하느냐 하는 것이다.
        - 샤딩 키 : 파티션 키(partition key)라고도 함. 데이터가 어떻게 분산할지를 정하는 하나이상의 칼럼으로 구성된다.
    - 샤딩 도입시 발생할 수 있는 문제
      - 데이터의 재 샤딩(resharding)
        - 데이터가 너무 많아져서 하나의 샤드로는 더 이상 감당하기 어려울때.
        - 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드에 비해 빨리 진행될 때. (샤드 소진(shard exhaustion)이라고 함)
      - Celebrity 문제
        - 핫스팟 키(hotspot key) 문제라기도 함.
        - 특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제.
      - 조인과 비정규화
        - 샤드로 나누게되면 조인이 힘들기에 비정규화하여 하나의 테이블에서 쿼리가 수행될 수 있도록 하는 것.

## 2장 개략적인 규모 추정

- 개략적인 규모 추정(back-of-the-envelope estimation)은 보편적으로 통용되는 성능 수치상에서 사고 실험(thought experiments)을 행하여 추정치를 계산하는 행위로서, 어떤 설계가 요구사항에 부합할 것인지 보기 위한 것. - 제프 딘
- 고가용성
  - 시스템이 오랜 시간 동안 지속적으로 중단 없이 운영될 수 있는 능력을 지칭하는 용어.

- 개략적인 규모 추정과 관계된 면접에서 가장 중요한 것은 문제를 풀어 나가는 절차이다. 면접자가 보고 싶어하는 것은 문제 해결 능력이다.
  - 팁
    - 근사치를 활용한 계산(rounding and approximation): 적절한 근사치를 활용하여 시간을 절약.
    - 가정(assumption): 적어두고 나중에 살펴볼 수 있도록 할것.
    - 단위(unit)을 붙여라.
    - QPS, 최대 QPS, 저장소 요구량, 캐시 요구량, 서버 수 등을 추정하는 것이 가장 많이 출제된다.

## 3장 시스템 설계 면접 공략법

- 시스템 설계 면접
  - 두 명의 동료가 모호한 문제를 풀기 위해 협력하여 그 해결책을 찾아내는 과정에 대한 시뮬레이션.
  - 설계 기술을 시연하는 자리이고, 설계 과정에서 내린 결정들에 대한 방어 능력을 보이는 자리이며, 면접관의 피드백을 건설적인 방식으로 처리할 자질이 있음을 보이는 자리.

- 면접관의 일차 목표는 여러분의 능력을 평가하는 것이다.

- 효과적인 면접을 위한 4단계 접근법
  - 1단계 문제 이해 및 설계 범위 확정
    - 요구 사항을 완전히 이해하지 않고 답을 내놓는 행위는 아주 엄청난 부정적 신호다.
    - 정답따위는 없다.
    - 깊이 생각하고 질문하여 요구사항과 가정들을 분명히 하라.
    - 엔지니어가 가져야 할 가장 중요한 기술 중 하나는 올바른 질문을 하는 것, 적절한 가정을 하는 것, 그리고 시스템 구축에 필요한 정보를 모으는 것이다.
  - 2단계 개략적인 설계안 제시 및 동의 구하기
    - 설계안에 대한 최초 청사진을 제시하고 의견 구하기
      - 면접관을 마치 팀원인 것처럼 대하라.
    - 화이트보드나 종이에 핵심 컴포넌트를 포함하는 다이어그램을 그려라.
    - 최초 설계안이 시스템 규모에 관계된 제약사항들을 만족하는지를 개략적으로 계산해 보라.
  - 3단계 상세 설계
    - 설계 대상 컴포넌트 사이의 우선순위를 정하는 것.
    - 특정 시스템 컴포넌트들의 세부사항을 깊이 있게 설명하는 것을 보길 원한다.
    - 시간 관리에도 특별히 주의를 기울여야 한다.
  - 4단계 마무리
    - 추가 논의 할 수 있는 몇가지 지침
      - 면접관이 시스템 병목구간, 혹은 좀 더 개선 가능한 지점을 찾아내라 주문할 수 있다. 거기다 대고 여러분의 설계가 완벽하다거나 개선할 부분이 없다는 답은 하지 않도록 하자.
      - 비판적 사고 능력을 보이고, 마지막으로 좋은 인상을 남길 기회다.
      - 만든 설계를 한번 다시 요약해주는 것도 도움이 될 수 있다.
      - 오류가 발생하면 무슨 일이 생기는지 따져보면 흥미로울 것이다.
      - 운영 이슈도 논의할 가치가 충분하다.
        - 메트릭은 어떻게 수집하고 모니터링 할 것인가? 로그는? 어떻게 배포할 것인가?
      - 미래에 닥칠 규모 확장 요구에 어떻게 대처할 것인가?
      - 시간이 남았을때, 필요하지만 다루지 못했던 세부적 개선사항들을 제안할 수 있다.
    - 면접 세션에서 해야할 것
      - 질문을 통해 확인(clarification)하라. 스스로 내린 가정이 옳다고 믿고 진행하지 말라.
      - 문제의 요구사항을 이해하라.
      - 정답이나 최선의 답안 같은 것은 없다는 점을 명심하라. 요구사항을 정확하게 이해했는지 다시 확인하라.
      - 면접관이 여러분의 사고 흐름을 이해할 수 있도록 하라.
      - 가능하다면 여러 해법을 함께 제시하라.
      - 개략적 설계에 면접관이 동의하면, 각 컴포넌트의 세부사항을 설명하기 시작하라. 가장 중요한 컴포넌트부터 진행하라.
      - 면접관의 아이디어를 이끌어 내라. 좋은 면접관은 여러분과 같은 팀원처럼 협력한다.
      - 포기하지 말라.
    - 면접 세션에서 하지 말아야 할 것
      - 전형적인 면접 문제들에도 대비하지 않은 상태에서 면접장에 가지 말라.
      - 요구사항이나 가정들을 분명히 하지 않은 상태에서 설계를 제시하지 말라.
      - 처음부터 특정 컴포넌트의 세부사항을 너무 깊이 설명하지 말라. 개략적 설계를 마친 뒤에 세부사항을 나아가라.
      - 진행 중에 막혔다면, 힌트를 청하기를 주저하지 말라.
      - 설계안을 내놓은 순간 면접이 끝난다고 생각하지 말라. 의견을 일찍, 그리고 자주 구하라.

## Ch4 처리율 제한 장치의 설계

- 처리율 제한 장치(rate limiter) : 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)를 제어하기 위한 장치
  - 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한하는 것과 같은 예임.
  - API 요청 횟수가 제한 장치에 정의된 임계치(threshold)를 넘어서면 추가로 도달한 모든 호출은 처리가 중단(block)된다.
- API에 처리율 제한 장치를 두면 좋은 점
  - DoS(Denial of service) 공격에 의한 자원 고갈(resource starvation)을 방지 가능
  - 비용 절감. 추가 요청에 대한 처리를 제한하면 서버를 많이 두지 않아도 되고, 우선순위가 높은 API에 더 많은 자원을 할당할 수 있다.
  - 서버 과부하를 막는다. bot에서 오는 트래픽이나 사용자의 잘못된 이용 패턴으로 유발된 트래픽을 걸러내는데 처리율 제한을 활용할 수 있다.

### 1단계 문제 이해 및 설계 범위 확정

- 시스템 요구사항
  - 설정된 처리율을 초과하는 요청은 정확하게 제한함.
  - 낮은 응답시간 - HTTP 응답시간에 나쁜 영향을 주어서는 안된다.
  - 가능한 한 적은 메모리를 사용해야한다.
  - 분산형 처리율 제한(distributed rate limiting) - 하나의 rate limiter로 여러 서버나 프로세스에서 공유할 수 있어야한다.
  - 예외 처리 - 요청이 제한되었을때, 그 사실을 사용자에게 분명하게 보여줘야 한다.
  - 높은 결함 감내성(fault tolerance) - rate limiter 에 장애가 발생하더라도 전체 시스템에 영향을 주어서는 안된다.

### 2단계 개략적 설계안 제시 및 동의 구하기

- 클라이언트 요청은 쉽게 위조가 가능하기에 rate limiter를 설정하는것은 위험하다.
- Rate limiter를 서버나, 미들웨어에 두어 통제하는것이 지금은 좋은 방법이다.
- Rate limiter 를 설계시 고려사항
  - 현재 사용하고 있는 기술 스택을 점검하여, 서버 측 구현을 지원하기 충분할 정도로 효율이 높은지 확인.
  - 서비스에 맞는 처리율 제한 알고리즘을 찾아라.
  - 마이크로서비스에 기반한 구성이라면, rate limiter 또한 게이트웨이 기능에 추가해야할 수 있다.
  - Rate limiter 서비스를 직접 만드는데는 시간이 든다. 상용 API 게이트웨이를 고려하라.

#### Rate limiter 알고리즘

- 토큰 버킷 token bucket
  - 동작 원리
    - 버킷에 토큰이 담길 수 있는 한계가 있고, 그것을 overflow 하게된다.
    - 토큰은 refill rate 를 통해서 특정 시간마다 초기화된다.
    - 하나의 요청이 들어오면 토큰 하나를 사용하게되고, 토큰이 하나도 없으면 drop 한다.
  - 인자
    - 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수
    - 토큰 공급률 (refill rate): 초당 몇 개의 토큰이 버킷에 공급되는가?
  - 사례
    - API 엔드포인트마다 별도의 버킷을 둔다.
      - 사용자마다 하루에 한 번 포스팅 (1 bucket)을 할 수 있고, 친구는 150명까지 추가 (1 bucket)할 수 있고, 좋아요 버튼은 다섯 번까지 (1 bucket)해서 사용자마다 3개의 버킷을 가지게됨.
  - 장점
    - 구현이 쉽다.
    - 메모리 사용 측면에서 효율적임.
    - 짧은 시간에 집중되는 트래픽 (burst of traffic)도 처리 가능. 버킷에 남은 토큰이 있기만 하면 요청은 시스템에 도달.
  - 단점
    - 두 개의 인자 (버킷 크기, 토큰 공급률)을 적절하게 튜닝하는 것이 까다롭다.

- 누출 버킷 leaky bucket
  - FIFO (First-In-First-Out) 큐로 구현.
  - 동작 원리
    - 요청을 받게 되면 큐에 요청을 추가하거나 가득차있으면 버린다.
    - 지정된 시간마다 큐에서 요청을 꺼내 처리한다.
  - 인자
    - 버킷 크기: 큐 사이즈와 같은 값
    - 처리율 (overflow rate): 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값. 초단위로 표현
  - 장점
    - 큐의 크기가 제한되어있어 메모리 사용량 측면에서 효율적
    - 고정된 처리율을 갖고 있기에 안정적인 출력(stable overflow rate)이 필요한 경우 적합함.
  - 단점
    - 단시간에 많은 트래픽이 몰리는 경우, 요청이 쌓이며, 그 요청들이 제때 처리되지 못할 경우, 최신 요청들이 버려지게 된다.
    - 두개의 인자를 올바르게 튜닝하기 까다로울 수 있음.

- 고정 윈도 카운터 fixed window counter
  - 동작 원리
    - 타임라인을 고정된 간격의 윈도(window)를 나누고, 각 윈도마다 카운터(counter)를 붙인다.
    - 요청이 접수될때마다 이 카운터의 값은 1씩 증가.
    - 이 카운터의 값이 사전에 설정된 임계치(threshold)에 도달하면 새로운 요청은 새 윈도가 열릴때까지 버려진다.
  - 장점
    - 메모리 효율이 좋다
    - 이해하기 쉽다
    - 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다
  - 단점
    - 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게된다.

- 이동 윈도 로그 sliding window log
  - 동작 원리
    - 요청의 타임스템프를 추적. 타임스템프 데이터는 보통 레디스의 정렬 집합과 같은 캐시에 보관.
    - 새요청이 오면 만료된 타임스탬프를 제거한다.
    - 새 요청의 타임스탬프를 로그에 추가한다
    - 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그렇지 않은 경우에는 처리를 거부한다.
  - 장점
    - 처리율 제한 메커니즘은 아주 정교하다. 어느 순간의 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.
  - 단점
    - 다량의 메모리를 사용하는데, 거부된 요청의 타임스탬프도 보관하기 때문임.

- 이동 윈도 카운터 sliding window counter
  - 고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한것.
  - 장점
    - 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.
    - 메모리 효율이 좋다
  - 단점
    - 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨함.

### 3단계 상세 설계

- 처리율 제한 규칙
- 처리율 한도 초과 트래픽의 처리
- 분산 환경에서의 처리율 제한 장치 구현
  - 두가지 어려운 문제가 있음.
  - 경쟁 조건(race condition)
    - 경쟁 조건 문제를 해결하는 방법은 lock이다.
    - 루아(Lua) 스크립트, 정렬 집합을 사용하는 것.
  - 동기화(synchronization)
- 성능 최적화
  - 지연시간
  - 최종 일관성 모델(eventual consistency model)
- 모니터링
  - 채택된 처리율 제한 알고리즘이 효과적
  - 정의한 처리율 제한 규칙이 효과적

### 4단계 마무리

- hard 또는 soft 처리율 제한
  - hard 처리율 제한: 요청 개수는 임계치를 절대 넘어설 수 없다.
  - soft 처리율 제한: 요청 개수는 잠시동안은 임계치를 넘어설 수 있다.
- 다양한 계층에서의 처리율 제한
- 처리율 제한을 회피하는 방법, 클라이언트를 어떻게 설계하는 것이 최선인가?

## 5장 안정 해시 설계

- 스케일 아웃을 위하여 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요함.

### 해시 키 재배치(rehash) 문제

- 해시 함수
  - `N`은 서버의 개수

```
serverIndex = hash(key) % N
```

- 서버 풀 크기가 고정되어있거나, 데이터 분포가 균등할때는 잘 동작함.
- 서버가 추가되거나 기존 서버가 삭제되면 문제가 발생하게됨.
  - 데이터가 다른 서버로 재분배가 되면서 클라이언트에서는 데이터가 없는 엉뚱한 서버에 접속할 가능성이 발생하게됨.

### 안정 해시

- 해시 테이블 크기가 조정될 떄 평균적으로 오직 k/n개의 키만 재배치하는 해시 기술이다. 여기서 k는 키의 개수이고, n은 슬롯(slot)의 개수다. 이와 달리 전통적인 해시 테이블은 슬롯의 수가 바뀌면 거의 대부분 키를 재배치한다.
- 해시 공간을 일렬로 구성하기도 하지만, 첫번째 공간과 마지막 공간을 연결해서 해시 링을 만들어서 설명을 하는데. 이건 설명을 쉽게 하려고 하는것같다.

- 안정 해시 알고리즘의 기본 절차
  - 서버와 키를 균등 분포(uniform distribution) 해시 함수를 사용해 해시 링에 배치한다.
  - 키의 위치에서 링을 시계 방향으로 탐색하다 만나는 최초의 서버의 키가 저장될 서버다.

- 기본 구현법의 두가지 문제
  1. 서버가 추가되거나 삭제되는 상황을 감안하면 파티션(partition)의 크기를 유지하는 게 불가능하다.
  - 파티션은 인접한 서버 사이의 해시 공간을 가르킨다.
  2. 키의 균등 분포(uniform distribution)을 달성하기가 어렵다.

- 문제 해결하기 위해 제안된 기법
  - 가상 노드: 실제 노드 또는 서버러를 가리키는 노드. 하나의 서버는 링 위에 여러개의 가상 노드를 가질 수 있다.
  - 가상 노드의 개수를 늘리면 키의 분포는 점점 더 균등해진다. 표준 편차가 작아져서 데이터가 더욱 균등하게 분포되기 때문임.

- 재배치할 키 결정
  - 항상 키는 서버의 시계 방향에 있는 서버로 배치된다.

### 안정 해시의 이점

- 서버가 추가되거나 삭제될 때 재배치되는 키의 수가 최소화된다.
- 데이터가 보다 균등하게 분포하게 되므로 수평적 규모 확장성을 달성하기 쉽다.
- 핫스팟 키 문제를 줄인다. 특정한 샤드에 대한 접근이나 지나치게 빈번하면서 서버 과부하 문제가 생길 수 있다. 안정 해시는 데이터를 좀 더 고르게 분배하므로 이런 문제가 생길 가능성을 줄인다.

## 6장 키-값 저장소 설계

- 키-값 저장소(key-value store)
  - 키-값 데이터베이스라고도 불리는 비 관계형(non-relational) 데이터베이스
  - 저장되는 값은 고유 식별자(identifier)를 키로 가져야한다. 이런 연결 관계를 "키-값" 쌍(pair)이라고 지칭한다.

- 키-값 쌍
  - 키는 유일해야하며 해당 키에 연결된 값은 키를 통해서만 접근할 수 있다.
  - 키는 일반 텍스트일 수도 있고 해시 갑실 수도 있다.
    - 성능사 이유로 키는 짧을수록 좋다.
  - 값은 문자열일 수도 있고 리스트(list)일 수도 있고 객체(object)일 수도 있다.
  - 값으로 무엇이 오든 상관하지 않는다.

### 문제 이해 및 설계 범위 확정

- 키-값 싸으이 크기는 10KB 이하이다.
- 큰 데이터를 저장할 수 있어야 한다.
- 높은 가용성을 제공해야 한다. 따라서 시스템은 설사 장애가 있더라도 빨리 응답해야 한다.
- 높은 규모 확장성을 제공해야 한다. 따라서 트래픽 양에 따라 자동적으로 서버 증설/삭제가 이루어져야 한다.
- 데이터 일관성 수준은 조정이 가능해야 한다.
- 응답 지연시간(latency)이 짧아야 한다.

### 단일 서버 키-값 저장소

- 가장 직관적인 방법: 키-값 쌍 전부를 메모리에 해시 테이블로 저장하는 것.
- 문제점: 모든 데이터를 메모리 안에 두는 것이 불가능할 수 있음.
- 개선책
  - 데이터 압축(compression)
  - 자주 쓰이는 데이터만 메모리에 두고 나머지는 디스크에 저장

### 분산 키-값 저장소

- CAP 정리
  - 데이터 일관성(consistency), 가용성(availability), 파티션 감내(partition tolerance)라는 세가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다는 정리.
    - 데이터 일관성: 분산 시스템에 접속하는 모든 클라이언트는 어떤 노드에 접속했느냐에 관계없이 언제나 같은 데이터를 보게 되어야 한다.
    - 가용성: 분산 시스템에 접속하는 클라이언트는 일부 노드에 장애가 발생하더라도 항상 응답을 받을 수 있어야 한다.
    - 파티션 감내: 파티션은 두 노드 사이에 통신 장애가 발생하였음을 의미한다. 네트워크에 파티션이 생기더라도 시스템은 계속 동작해야 한다는 것을 뜻한다.
  - 이들 가운데 어떤 두 가지를 충족하려면 나머지 하나는 반드시 희생되어야 하다는 것을 의미.
  - 어느 두가지를 만족하느냐에 따라 다음과 같이 분류 가능하다.
    - CP 시스템: 일관성과 파티션 감내를 지원하는 키-값 저장소. 가용성을 희생한다.
    - AP 시스템: 가용성과 파티션 감내를 지원하는 키-값 저장소. 데이터 일관성을 희생한다.
    - CA 시스템: 일관성과 가용성을 지원하는 키-값 저장소. 파티션 감내는 지원하지 않는다.
      - 네트워크 장애는 피할 수 없는 일로 여겨지므로, 실설계에 CA 시스템은 존재하지 않는다.

- 실세계의 분산 시스템
  - 파티션 문제를 피할 수 없다. 그리고 파티션 문제가 발생하면 우리는 일관성과 가용성 사이에서 하나를 선택해야 한다.

### 시스템 컴포넌트

- 데이터 파티션
  - 전체 데이터를 한 대 서버에 욱여넣는 것은 불가능하다. 해결책은 데이터를 작은 파티션들로 분할한 다음 여러 대 서버에 저장하는 것.
  - 안정 해시를 사용하여 데이터를 파티션할 경우 좋은 점
    - 규모 확장 자동화 (automatic scaling): 시스템 부하에 따라 서버가 자동으로 추가되거나 삭제되도록 만들수 있다.
    - 다양성 (heterogeneity): 각 서버의 용량에 맞게 가상 노드의 수를 조정할 수 있다.
- 데이터 다중화
  - 높은 가용성과 안정성을 확보하기 위해서는 데이터를 N개 서버에 비동기적으로 다중화(replication)할 필요가 있음.
- 데이터 일관성
  - 정족수 합의 (quorum consensus) 프로토콜을 사용하면 읽기/쓰기 연산 모두 일관성을 보장할 수 있다.
  - 관계된 정의
    - N = 사본의 개수
    - W = 쓰기 연산에 대한 정족수. 쓰기 연산이 성공한 것으로 간주되려면 적어도 W개의 서버로부터 쓰기 연산이 성공했다는 응답을 받아야 한다.
    - R = 읽기 연산에 대한 정족수. 읽기 연산은 성공한 것으로 간주되려면 적어도 R개의 서버로부터 응답을 받아야 한다.
  - W, R, N 값을 정하는 것은 응답 지연과 데이터 일관성 사이의 타협점을 찾는 전형적인 과정.
  - 일관성 모델
    - 데이터 일관성의 수준을 결정함.
    - 강한 일관성 (strong consistency) : 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환한다. 클라이언트는 절대로 낡은(out-of-date) 데이터를 보지 못한다.
    - 약한 일관성 (weak consistency): 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있다.
    - 최종 일관성 (eventual consistency): 약한 일관성의 한 형태로, 갱신 결과가 결국에는 모든 사본에 반영(즉, 동기화)되는 모델이다.
  - 강한 일관성을 달성하는 일반적인 방법: 모든 사본에 현재 쓰기 연산의 결과가 반영될 때까지 해당 데이터에 대한 읽기/쓰기를 금지하는 것.
  - 비 일관 해소 기법: 데이터 버저닝
    - 데이터를 다중화하면 가용성은 높아지지만 사본 간 일관성이 깨질 가능성은 높아짐.
    - 버저닝(versioning): 데이터를 변경할 때마다 해당 데이터의 새로운 버전을 만드는 것을 의미함. 각 버전의 데이터는 변경 불가능(immutable)하다.
    - 벡터 시계(vector clock): `[서버: 버전]`의 순서쌍을 데이터에 매단 것임. 어떤 버전이 선행 버전인지, 후행 버전인지, 아니면 다른 버전과 충돌이 있는지 판별하는데 사용함.
    - 백터 시계를 사용해 충돌을 감지하고 해소하는 방법
      - 충돌 감지 및 해소 로직이 클라이언트에 들어가야 하므로, 클라이언트 구현이 복잡해진다는 것.
      - `[서버: 버전]`의 순서쌍 개수가 굉장히 빨리 늘어난다는 것.
  - 장애 처리
    - 장애 감지
      - 보통 두 대 이상의 서버가 똑같이 서버 A의 장애를 보고해야 해당 서버에 실제로 장애가 발생했다고 간주하게 된다.
      - heartbeat counter를 이용해서 서버의 상태를 파악하게됨.
    - 일시적 장애 처리
      - 느슨한 정족수(sloppy quorum) 접근법은 읽기와 쓰기 연산 조건을 완화하여 가용성을 높임.
      - 네트워크나 서버 문제로 장애 상태인 서버로 가는 요청은 다른 서버가 잠시 맡아 처리. 그동안 발생한 변경사항은 해당 서버가 복구되었을때 일괄 반영하여 데이터 일관성을 보존함.
    - 영구 장애 처리
      - 반-엔트로피(anti-entropy) 프로토콜: 사본들을 비교하여 최신 버전으로 갱신하는 과정을 포함함.
      - 사본 간의 일관성이 망가진 상태를 탐지하고 전송 데이터의 양을 줄이기 위해서 머클(merkle) 트리를 사용할 것.

## 7장 분산 시스템을 위한 유일 ID 생성기 설계

### 1단계 문제 이해 및 설계 범위 확정

#### 요구사항

- ID는 유일 해야한다. 숫자로만 구성되어야 한다. 64비트로 표현될 수 있는 값이어야 한다. 발급 날짜에 따라 정렬 가능해야 한다.
- 초당 10_000개의 ID를 만들 수 있어야 한다.

### 2단계 개략적 설계안 제시 및 동의 구하기

#### 다중 마스터 복제 (multi-master replication)

- 데이터베이스의 `auto_increment` 기능을 활용하는 것. 다음 ID의 값을 구할때, k만큼 증가.

##### 단점

- 여러 데이터 센터에 걸쳐 규모를 늘리기 어렵다.
- ID의 유일성은 보장되겠지만 그 값이 시간 흐름에 맞춰 커지도록 보장할 수는 없다.
- 서버를 추가하거나 삭제할 때도 잘 동작하도록 만들기 어렵다.

#### UUID

- 각 웹서버에서 별도의 ID 생성기를 사용해 독립적으로 ID를 만들어냄.

##### 장점

- UUID를 만드는 것은 단순하다. 서버 사이의 종률이 필요 없으므로 동기화 이슈도 없다.
- 각 서버가 자기가 쓸 ID를 알아서 만드는 구조이므로 규모 확장도 쉽다.

##### 단점

- ID가 길다 (128bit). 이번 장에서 다루는 것은 64bit.
- ID를 시간순으로 정렬할 수 없다. (UUIDv7은 타임이 들어감)
- ID에 숫자(numeric)아니 값이 포함될 수 있다.

#### 티켓 서버 (ticket server)

- 중앙 집중형으로 `auto_increment` 기능을 갖춘 데이터베이스 서버를 사용하는 것.

##### 장점

- 유일성이 보장되는 오직 숫자로만 구성된 ID를 쉽게 만들 수 있다.
- 구현하기 쉽고, 중소 규모 애플리케이션에 적합하다.

##### 단점

- 티켓 서버가 SPOF(Single-Point-of-Failure)

#### 트위터 스노플레이크 접근법

- 스노플레이크(snowflake)라고 부르는 독창적인 ID 생성 기법을 의미한다.
- ID 구조
  - sign: 1 bit. 나중에 구분을 위해서 남겨둠.
  - timestamp: 41 bit. epoch(기원 시각) 이후 밀리초 단위에 대해서 남김.
  - 데이터센터 ID: 5 bit.
  - 서버 ID: 5 bit.
  - 일련번호: 12 bit. ID 생성때마다 1만큼 증가. 1ms가 경과할 떄마다 0으로 초기화.

### 3단계 상세 설계

타임 스템프

- 시간이 흐름에 따라 점점 큰 값을 가지게 되어 시간순으로 정렬이 가능해짐.

일련번호

- 같은 서버에서 밀리초 동안 하나 이상의 ID를 만들어 낸 경우에만 0보다 큰 값을 갖게 된다.

### 4단계 마무리

추가 논의사항

- 시계 동기화 (clock synchronization): NTP(Network Time Protocol)을 이용하면 된다.
- 각 section의 길이 최적화
  - 동시성이 낮고 수명이 긴 애플리케이션이라면 일련번호 절의 길이를 줄이고 타임 스템프 절의 길이를 늘리는 것이 효과적일 수 있다.
- 고가용성(high availability): ID 생성기는 필수 불가결(mission critical) 컴포넌트이므로 아주 높은 가용성을 제공해야한다.

## 8장 URL 단축기 설계

### 1단계 문자 이해 및 설계 범위 확정

- 쓰기 연산: 매일 1억 개의 단축 URL 생성
- 초당 쓰기 연산: 1억 / 24 / 3600 = 1160
- 읽기 연산: `읽기:쓰기` = `10:1` => 읽기 연산은 초당 11600
- 10년 운영시 3650억 개의 레코드를 보관
- 축약전 URL의 평균 길이: 100
- 10년동안 필요한 저장 용량: 36.5TB

### 2단계 개략적 설계안 제시 및 동의 구하기

#### API 엔드포인트

1. URL 단축용 엔드포인트

- `POST /api/v1/data/shorten`
  - 인자: `{longUrl: longURLstring}`
  - 반환: 단축 URL

2. URL 디리렉션용 엔드포인트

- `GET /api/v1/shortUrl`
  - 반환: HTTP 리디렉션 목적지가 될 원래 URL

#### URL 리디렉션

입력된 URL에 매칭되는 원래 URL로 바꾸어서 301이나 302로 응답을 넣어서 동작하게된다.

- 301 Permanently Move 응답
  - 해당 URL에 대한 HTTP 요청 처리 책임이 영구적으로 Location 헤더에 반환된 URL로 이전되었다는 응답.
  - 영구적으로 이전되었으므로, 브라우저는 이 응답을 캐시하여 사용하게 된다.
- 302 Found 응답
  - 주어진 URL로의 요청이 '일시적으로' Location 헤더가 지정하는 URL에 의해 처리되어야 한다는 응답.
  - 클라이언트에서는 언제나 단축 URL 서버에 먼저 보내진 후에 원래 URL로 리디렉션 되어야 한다.

#### URL 단축 플로

URL을 해시값으로 대응할 수 있는 함수를 찾는것이 중요하다.

해시 함수에서 만족되어야하는 요구사항

- 입력으로 주어지는 긴 URL이 다른 값이면 해시 값도 달라야 한다.
- 계산된 해시 값은 원래 입력으로 주어졌던 긴 URL로 복원될 수 있어야 한다.

### 3단계 상세 설계

#### 데이터 모델

RDB에 <단축 URL, 원래 URL> 순서쌍을 저장.
컬럼은 `id`, `shortURL`, `longURL`

#### 해시 함수

- hashValue: 해시 함수가 계산하는 단축 URL 값

**해시 값 길이**

`[0-9,a-z,A-Z]` 의 문자로 구성되며, 개수는 62개
3650개의 URL을 만들어 낼 수 있어야 하기에 62^7 개 정도면 가능하다.
따라서 `len(hashValue) = 7`

**충돌 해소 방법**

**1. 해시 후 충돌 해소**

해시 함수를 이용하여 결과값을 저장한다.
충돌이 일어날 경우, 사전에 정의한 문자열을 해시 값에 덧붙여 피한다.

**2. base-62 변환**

62진법으로 변경하여 데이터를 저장하는 것.

#### URL 단축기 상세 설계

### 4단계 마무리

**더 이야기할만한 것들**

- 처리율 제한 장치
- 웹 서버 규모 확장
- 데이터베이스의 규모 확장
- 데이터 분석 솔루션
- 가용성, 데이터 일관성, 안정성
